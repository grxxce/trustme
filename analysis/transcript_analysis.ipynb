{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No participant number 39\n",
      "Number of participant transcripts: 48\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"./survey_data.csv\"  # Replace with your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()\n",
    "\n",
    "\n",
    "# Load in all of the transcripts as a dictionary of arrays, with each line separated into an array element.\n",
    "complete_transcripts = {}\n",
    "\n",
    "for i in range(1, 50):\n",
    "    filename = f\"./transcripts/p{i}.csv\"\n",
    "    transcript = []\n",
    "    try: \n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                if \":\" in line:\n",
    "                    transcript.append(line)\n",
    "        complete_transcripts[f\"P{i}\"] = transcript\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No participant number {i}\")\n",
    "    \n",
    "# print(complete_transcripts[22])\n",
    "print(f\"Number of participant transcripts: {len(complete_transcripts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Participants: 37\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Clean Data?' is TRUE\n",
    "clean_data = data[data['Clean Data?'] == True].copy()\n",
    "\n",
    "# Calculate the number of flipped choices per participant\n",
    "clean_data['Total Flipped Choices'] = (\n",
    "    clean_data['Q1 Flipped Choice?'].astype(int) +\n",
    "    clean_data['Q2 Flipped Choice?'].astype(int) +\n",
    "    clean_data['Q3 Flipped Choice?'].astype(int)\n",
    ")\n",
    "\n",
    "clean_transcripts = {}\n",
    "for participant in clean_data[\"Participant Number\"]:\n",
    "    if participant in complete_transcripts:\n",
    "        clean_transcripts[participant] = complete_transcripts[participant]\n",
    "\n",
    "print(f\"Clean Participants: {len(clean_transcripts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant information from the transcripts, such as the before-and-after explanations.\n",
    "q1_pre_explanations = {}\n",
    "q1_post_explanations = {}\n",
    "q2_pre_explanations = {}\n",
    "q2_post_explanations = {}\n",
    "q3_pre_explanations = {}\n",
    "q3_post_explanations = {}\n",
    "\n",
    "# To help automate this process.\n",
    "explanation_vars = [q1_pre_explanations, q1_post_explanations, q2_pre_explanations, q2_post_explanations, q3_pre_explanations, q3_post_explanations]\n",
    "\n",
    "for participant in clean_transcripts:\n",
    "    # Participant transcript\n",
    "    transcript = clean_transcripts[participant]\n",
    "\n",
    "    # Initialize an empty list to store the user responses\n",
    "    responses = []\n",
    "\n",
    "    # Iterate through the lines and find the relevant responses\n",
    "    for i in range(len(transcript)):\n",
    "        if transcript[i].strip() == \"Bot: Why do you choose that?\":\n",
    "            # Ensure the next line is a User response\n",
    "            if i + 1 < len(transcript) and transcript[i + 1].startswith(\"User:\"):\n",
    "                # Extract the explanation\n",
    "                responses.append(transcript[i + 1].replace(\"User: \", \"\").strip())\n",
    "\n",
    "    # Store responses in separate variables\n",
    "    for i in range(len(explanation_vars)):\n",
    "        explanation_vars[i][participant] = responses[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Explanations - Question One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Overall\n",
      "Q1: Analyzing the results, we see that 15 post-explanations were shorter.\n",
      "Q1: We see that 21 explanations were longer in the post-questioning.\n",
      "\n",
      "--- Modality\n",
      "Audio modality yielded 13 responses where the post-explanation was longer.\n",
      "Text modality yielded 8 responses where the post-explanation was longer.\n",
      "\n",
      "--- Familiarity\n",
      "Highly familiar (4 and 5) users had 56.52173913043478% of responses where the post-explanation was longer.\n",
      "Somewhat familiar (3) users had 80.0% of responses where the post-explanation was longer.\n",
      "Less familiar (1 and 2) users had 44.44444444444444% of responses where the post-explanation was longer.\n"
     ]
    }
   ],
   "source": [
    "# Analyze the results and output the explanations to a file for easier understanding.\n",
    "\n",
    "# Analyzing each question separately.\n",
    "q1_shorter_responses_count = 0\n",
    "q1_longer_response_count = 0\n",
    "\n",
    "# Analyze by modality\n",
    "q1_audio_longer_count = 0\n",
    "q1_text_longer_count = 0\n",
    "\n",
    "# Analyze by familiarity\n",
    "q1_high_familiarity_longer_count = 0\n",
    "q1_somewhat_familiar_longer_count = 0\n",
    "q1_low_familiarity_longer_count = 0\n",
    "\n",
    "with open(\"question_one_explanations.txt\", \"w\") as file:\n",
    "    for participant in q1_pre_explanations:\n",
    "        if not participant in q1_post_explanations:\n",
    "            print(f\"Missing post explanation for {participant}\")\n",
    "            continue \n",
    "        \n",
    "        # Get modality of this participant\n",
    "        modality = clean_transcripts[participant][1]\n",
    "        # Get familiarity\n",
    "        familiarity = clean_transcripts[participant][3]\n",
    "        familiarity_num = int(familiarity.split(\":\")[1].strip())\n",
    "\n",
    "        # Get the lengths of explanations\n",
    "        before_length = len(q1_pre_explanations[participant].split())\n",
    "        after_length = len(q1_post_explanations[participant].split())\n",
    "        \n",
    "        # Compare the lengths and update them, considering modality\n",
    "        if after_length > before_length:\n",
    "            q1_longer_response_count += 1\n",
    "            # Consider modality\n",
    "            if \"Audio\" in modality:\n",
    "                q1_audio_longer_count += 1\n",
    "            elif \"Text\" in modality:\n",
    "                q1_text_longer_count += 1\n",
    "            # Consider familiarity\n",
    "            if familiarity_num > 3:\n",
    "                q1_high_familiarity_longer_count += 1\n",
    "            elif familiarity_num == 3:\n",
    "                q1_somewhat_familiar_longer_count += 1\n",
    "            else:\n",
    "                q1_low_familiarity_longer_count += 1\n",
    "        elif before_length > after_length:\n",
    "            q1_shorter_responses_count += 1\n",
    "\n",
    "        # Write responses to our file.\n",
    "        file.write(f\"Participant {participant}\\n\")\n",
    "        file.write(modality)\n",
    "        file.write(familiarity)\n",
    "        file.write(f\"Before: {q1_pre_explanations[participant]}\\n\")\n",
    "        file.write(f\"After: {q1_post_explanations[participant]}\\n\")\n",
    "        file.write(f\"Comparison: Word count is {before_length} words before and {after_length} words after.\\n\")\n",
    "        file.write(\"\\n---\\n\\n\") \n",
    "\n",
    "print(\"--- Overall\")\n",
    "print(f\"Q1: Analyzing the results, we see that {q1_shorter_responses_count} post-explanations were shorter.\")\n",
    "print(f\"Q1: We see that {q1_longer_response_count} explanations were longer in the post-questioning.\")\n",
    "print(\"\\n--- Modality\")\n",
    "print(f\"Audio modality yielded {q1_audio_longer_count} responses where the post-explanation was longer.\")\n",
    "print(f\"Text modality yielded {q1_text_longer_count} responses where the post-explanation was longer.\")\n",
    "\n",
    "# Due to having a different number of participants of familiarity levels, we must normalize.\n",
    "participant_count_by_experience_group = clean_data.groupby(\"Experience with LLMs\").size()\n",
    "participant_high_familiarity = participant_count_by_experience_group[5.0] + participant_count_by_experience_group[4.0]\n",
    "participant_somewhat = participant_count_by_experience_group[3.0]\n",
    "participant_low = participant_count_by_experience_group[2.0] + participant_count_by_experience_group[1.0]\n",
    "\n",
    "q1_high_normalized = q1_high_familiarity_longer_count / participant_high_familiarity\n",
    "q1_somewhat_normalized = q1_somewhat_familiar_longer_count / participant_somewhat\n",
    "q1_low_normalized = q1_low_familiarity_longer_count / participant_low\n",
    "print(\"\\n--- Familiarity\")\n",
    "print(f\"Highly familiar (4 and 5) users had {q1_high_normalized * 100}% of responses where the post-explanation was longer.\")\n",
    "print(f\"Somewhat familiar (3) users had {q1_somewhat_normalized * 100}% of responses where the post-explanation was longer.\")\n",
    "print(f\"Less familiar (1 and 2) users had {q1_low_normalized * 100}% of responses where the post-explanation was longer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Explanations - Question Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Overall\n",
      "Q2: Analyzing the results, we see that 22 post-explanations were shorter.\n",
      "Q2: We see that 15 explanations were longer in the post-questioning.\n",
      "\n",
      "--- Modality\n",
      "Audio modality yielded 10 responses where the post-explanation was longer.\n",
      "Text modality yielded 5 responses where the post-explanation was longer.\n",
      "\n",
      "--- Familiarity\n",
      "Highly familiar (4 and 5) users had 39.130434782608695% of responses where the post-explanation was longer.\n",
      "Somewhat familiar (3) users had 20.0% of responses where the post-explanation was longer.\n",
      "Less familiar (1 and 2) users had 55.55555555555556% of responses where the post-explanation was longer.\n"
     ]
    }
   ],
   "source": [
    "# Analyze the results and output the explanations to a file for easier understanding.\n",
    "\n",
    "# Analyzing each question separately.\n",
    "q2_shorter_responses_count = 0\n",
    "q2_longer_response_count = 0\n",
    "\n",
    "# Analyze by modality\n",
    "q2_audio_longer_count = 0\n",
    "q2_text_longer_count = 0\n",
    "\n",
    "# Analyze by familiarity\n",
    "q2_high_familiarity_longer_count = 0\n",
    "q2_somewhat_familiar_longer_count = 0\n",
    "q2_low_familiarity_longer_count = 0\n",
    "\n",
    "with open(\"question_two_explanations.txt\", \"w\") as file:\n",
    "    for participant in q2_pre_explanations:\n",
    "        if not participant in q2_post_explanations:\n",
    "            print(f\"Missing post explanation for {participant}\")\n",
    "            continue \n",
    "        \n",
    "        # Get modality of this participant\n",
    "        modality = clean_transcripts[participant][1]\n",
    "        # Get familiarity\n",
    "        familiarity = clean_transcripts[participant][3]\n",
    "        familiarity_num = int(familiarity.split(\":\")[1].strip())\n",
    "\n",
    "        # Get the lengths of explanations\n",
    "        before_length = len(q2_pre_explanations[participant].split())\n",
    "        after_length = len(q2_post_explanations[participant].split())\n",
    "        # Compare the lengths\n",
    "        if after_length > before_length:\n",
    "            q2_longer_response_count += 1\n",
    "            if \"Audio\" in modality:\n",
    "                q2_audio_longer_count += 1\n",
    "            elif \"Text\" in modality:\n",
    "                q2_text_longer_count += 1\n",
    "            # Consider familiarity\n",
    "            if familiarity_num > 3:\n",
    "                q2_high_familiarity_longer_count += 1\n",
    "            elif familiarity_num == 3:\n",
    "                q2_somewhat_familiar_longer_count += 1\n",
    "            else:\n",
    "                q2_low_familiarity_longer_count += 1\n",
    "        elif before_length > after_length:\n",
    "            q2_shorter_responses_count += 1\n",
    "\n",
    "        # Write responses to our file.\n",
    "        file.write(f\"Participant {participant}\\n\")\n",
    "        file.write(modality)\n",
    "        file.write(familiarity)\n",
    "        file.write(f\"Before: {q2_pre_explanations[participant]}\\n\")\n",
    "        file.write(f\"After: {q2_post_explanations[participant]}\\n\")\n",
    "        file.write(f\"Comparison: Word count is {before_length} words before and {after_length} words after.\\n\")\n",
    "        file.write(\"\\n---\\n\\n\") \n",
    "\n",
    "print(\"--- Overall\")\n",
    "print(f\"Q2: Analyzing the results, we see that {q2_shorter_responses_count} post-explanations were shorter.\")\n",
    "print(f\"Q2: We see that {q2_longer_response_count} explanations were longer in the post-questioning.\")\n",
    "\n",
    "print(\"\\n--- Modality\")\n",
    "print(f\"Audio modality yielded {q2_audio_longer_count} responses where the post-explanation was longer.\")\n",
    "print(f\"Text modality yielded {q2_text_longer_count} responses where the post-explanation was longer.\")\n",
    "\n",
    "# Analyze familiarity\n",
    "q2_high_normalized = q2_high_familiarity_longer_count / participant_high_familiarity\n",
    "q2_somewhat_normalized = q2_somewhat_familiar_longer_count / participant_somewhat\n",
    "q2_low_normalized = q2_low_familiarity_longer_count / participant_low\n",
    "print(\"\\n--- Familiarity\")\n",
    "print(f\"Highly familiar (4 and 5) users had {q2_high_normalized * 100}% of responses where the post-explanation was longer.\")\n",
    "print(f\"Somewhat familiar (3) users had {q2_somewhat_normalized * 100}% of responses where the post-explanation was longer.\")\n",
    "print(f\"Less familiar (1 and 2) users had {q2_low_normalized * 100}% of responses where the post-explanation was longer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Explanations - Question Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Overall\n",
      "Q3: Analyzing the results, we see that 24 post-explanations were shorter.\n",
      "Q3: We see that 11 explanations were longer in the post-questioning.\n",
      "\n",
      "--- Modality\n",
      "Audio modality yielded 8 responses where the post-explanation was longer.\n",
      "Text modality yielded 3 responses where the post-explanation was longer.\n",
      "\n",
      "--- Familiarity\n",
      "Highly familiar (4 and 5) users had 21.73913043478261% of responses where the post-explanation was longer.\n",
      "Somewhat familiar (3) users had 40.0% of responses where the post-explanation was longer.\n",
      "Less familiar (1 and 2) users had 44.44444444444444% of responses where the post-explanation was longer.\n"
     ]
    }
   ],
   "source": [
    "# Analyze the results and output the explanations to a file for easier understanding.\n",
    "\n",
    "# Analyzing each question separately.\n",
    "q3_shorter_responses_count = 0\n",
    "q3_longer_response_count = 0\n",
    "\n",
    "# Analyze by modality\n",
    "q3_audio_longer_count = 0\n",
    "q3_text_longer_count = 0\n",
    "\n",
    "# Analyze by familiarity\n",
    "q3_high_familiarity_longer_count = 0\n",
    "q3_somewhat_familiar_longer_count = 0\n",
    "q3_low_familiarity_longer_count = 0\n",
    "\n",
    "with open(\"question_three_explanations.txt\", \"w\") as file:\n",
    "    for participant in q3_pre_explanations:\n",
    "        if not participant in q3_post_explanations:\n",
    "            print(f\"Missing post explanation for {participant}\")\n",
    "            continue \n",
    "\n",
    "        # Get modality of this participant\n",
    "        modality = clean_transcripts[participant][1]\n",
    "        # Get familiarity\n",
    "        familiarity = clean_transcripts[participant][3]\n",
    "        familiarity_num = int(familiarity.split(\":\")[1].strip())\n",
    "\n",
    "        # Get the lengths of explanations\n",
    "        before_length = len(q3_pre_explanations[participant].split())\n",
    "        after_length = len(q3_post_explanations[participant].split())\n",
    "        # Compare the lengths\n",
    "        if after_length > before_length:\n",
    "            q3_longer_response_count += 1\n",
    "            if \"Audio\" in modality:\n",
    "                q3_audio_longer_count += 1\n",
    "            elif \"Text\" in modality:\n",
    "                q3_text_longer_count += 1\n",
    "            # Consider familiarity\n",
    "            if familiarity_num > 3:\n",
    "                q3_high_familiarity_longer_count += 1\n",
    "            elif familiarity_num == 3:\n",
    "                q3_somewhat_familiar_longer_count += 1\n",
    "            else:\n",
    "                q3_low_familiarity_longer_count += 1\n",
    "        elif before_length > after_length:\n",
    "            q3_shorter_responses_count += 1\n",
    "\n",
    "        # Write responses to our file.\n",
    "        file.write(f\"Participant {participant}\\n\")\n",
    "        file.write(modality)\n",
    "        file.write(familiarity)\n",
    "        file.write(f\"Before: {q3_pre_explanations[participant]}\\n\")\n",
    "        file.write(f\"After: {q3_post_explanations[participant]}\\n\")\n",
    "        file.write(f\"Comparison: Word count is {before_length} words before and {after_length} words after.\\n\")\n",
    "        file.write(\"\\n---\\n\\n\") \n",
    "\n",
    "print(\"--- Overall\")\n",
    "print(f\"Q3: Analyzing the results, we see that {q3_shorter_responses_count} post-explanations were shorter.\")\n",
    "print(f\"Q3: We see that {q3_longer_response_count} explanations were longer in the post-questioning.\")\n",
    "print(\"\\n--- Modality\")\n",
    "print(f\"Audio modality yielded {q3_audio_longer_count} responses where the post-explanation was longer.\")\n",
    "print(f\"Text modality yielded {q3_text_longer_count} responses where the post-explanation was longer.\")\n",
    "# Analyze familiarity\n",
    "q3_high_normalized = q3_high_familiarity_longer_count / participant_high_familiarity\n",
    "q3_somewhat_normalized = q3_somewhat_familiar_longer_count / participant_somewhat\n",
    "q3_low_normalized = q3_low_familiarity_longer_count / participant_low\n",
    "print(\"\\n--- Familiarity\")\n",
    "print(f\"Highly familiar (4 and 5) users had {q3_high_normalized * 100}% of responses where the post-explanation was longer.\")\n",
    "print(f\"Somewhat familiar (3) users had {q3_somewhat_normalized * 100}% of responses where the post-explanation was longer.\")\n",
    "print(f\"Less familiar (1 and 2) users had {q3_low_normalized * 100}% of responses where the post-explanation was longer.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
